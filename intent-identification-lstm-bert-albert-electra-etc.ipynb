{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1119749,"sourceType":"datasetVersion","datasetId":628714}],"dockerImageVersionId":29908,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport os\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Embedding, Activation, LSTM, SimpleRNN, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nimport tensorflow_hub as hub\nprint(\"TensorFlow Version:\",tf.__version__)\nprint(\"Hub version: \",hub.__version__)\n# Params for bert model and tokenization\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-04-07T07:17:46.645776Z","iopub.execute_input":"2024-04-07T07:17:46.646155Z","iopub.status.idle":"2024-04-07T07:17:46.655827Z","shell.execute_reply.started":"2024-04-07T07:17:46.646110Z","shell.execute_reply":"2024-04-07T07:17:46.655049Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"TensorFlow Version: 2.1.0\nHub version:  0.8.0\n","output_type":"stream"}]},{"cell_type":"code","source":"class LoadingData():\n            \n    def __init__(self):\n        train_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Train\")\n        validation_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Validate\")\n        category_id = 0\n        self.cat_to_intent = {}\n        self.intent_to_cat = {}\n        \n        for dirname, _, filenames in os.walk(train_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                self.cat_to_intent[category_id] = intent_id\n                self.intent_to_cat[intent_id] = category_id\n                category_id+=1\n        print(self.cat_to_intent)\n        print(self.intent_to_cat)\n        '''Training data'''\n        training_data = list() \n        for dirname, _, filenames in os.walk(train_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                training_data+=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])\n        self.train_data_frame = pd.DataFrame(training_data, columns =['query', 'intent','category'])   \n        \n        self.train_data_frame = self.train_data_frame.sample(frac = 1)\n\n\n        \n        '''Validation data'''\n        validation_data = list()    \n        for dirname, _, filenames in os.walk(validation_file_path):\n            for filename in filenames:\n                file_path = os.path.join(dirname, filename)\n                intent_id = filename.replace(\".json\",\"\")\n                validation_data +=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])                \n        self.validation_data_frame = pd.DataFrame(validation_data, columns =['query', 'intent','category'])\n\n        self.validation_data_frame = self.validation_data_frame.sample(frac = 1)\n        \n        \n    def make_data_for_intent_from_json(self,json_file,intent_id,cat):\n        json_d = json.load(open(json_file))         \n        \n        json_dict = json_d[intent_id]\n\n        sent_list = list()\n        for i in json_dict:\n            each_list = i['data']\n            sent =\"\"\n            for i in each_list:\n                sent = sent + i['text']+ \" \"\n            sent =sent[:-1]\n            for i in range(3):\n                sent = sent.replace(\"  \",\" \")\n            sent_list.append((sent,intent_id,cat))\n        return sent_list\n            ","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-04-07T07:17:47.092394Z","iopub.execute_input":"2024-04-07T07:17:47.092792Z","iopub.status.idle":"2024-04-07T07:17:47.113652Z","shell.execute_reply.started":"2024-04-07T07:17:47.092732Z","shell.execute_reply":"2024-04-07T07:17:47.112798Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"load_data_obj = LoadingData()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:47.638136Z","iopub.execute_input":"2024-04-07T07:17:47.638578Z","iopub.status.idle":"2024-04-07T07:17:48.001177Z","shell.execute_reply.started":"2024-04-07T07:17:47.638505Z","shell.execute_reply":"2024-04-07T07:17:48.000444Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{0: 'BookRestaurant', 1: 'SearchScreeningEvent', 2: 'RateBook', 3: 'GetWeather', 4: 'AddToPlaylist', 5: 'PlayMusic', 6: 'SearchCreativeWork'}\n{'BookRestaurant': 0, 'SearchScreeningEvent': 1, 'RateBook': 2, 'GetWeather': 3, 'AddToPlaylist': 4, 'PlayMusic': 5, 'SearchCreativeWork': 6}\n","output_type":"stream"}]},{"cell_type":"code","source":"load_data_obj.train_data_frame.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:48.003025Z","iopub.execute_input":"2024-04-07T07:17:48.003326Z","iopub.status.idle":"2024-04-07T07:17:48.017794Z","shell.execute_reply.started":"2024-04-07T07:17:48.003277Z","shell.execute_reply":"2024-04-07T07:17:48.016836Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                   query  \\\n12271            find the painting Sleeping in Your Hand   \n11003             Open Deezer and play Inyeccion Musical   \n3109   Find the schedule for The Cup Winner at the cl...   \n13484  Can you find me the game , Super Scription of ...   \n2948   will Dick Tracy e il gas misterioso start twen...   \n\n                     intent  category  \n12271    SearchCreativeWork         6  \n11003             PlayMusic         5  \n3109   SearchScreeningEvent         1  \n13484    SearchCreativeWork         6  \n2948   SearchScreeningEvent         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query</th>\n      <th>intent</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12271</th>\n      <td>find the painting Sleeping in Your Hand</td>\n      <td>SearchCreativeWork</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11003</th>\n      <td>Open Deezer and play Inyeccion Musical</td>\n      <td>PlayMusic</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3109</th>\n      <td>Find the schedule for The Cup Winner at the cl...</td>\n      <td>SearchScreeningEvent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13484</th>\n      <td>Can you find me the game , Super Scription of ...</td>\n      <td>SearchCreativeWork</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2948</th>\n      <td>will Dick Tracy e il gas misterioso start twen...</td>\n      <td>SearchScreeningEvent</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"load_data_obj.train_data_frame","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:48.143842Z","iopub.execute_input":"2024-04-07T07:17:48.144180Z","iopub.status.idle":"2024-04-07T07:17:48.157672Z","shell.execute_reply.started":"2024-04-07T07:17:48.144128Z","shell.execute_reply":"2024-04-07T07:17:48.156695Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                   query  \\\n12271            find the painting Sleeping in Your Hand   \n11003             Open Deezer and play Inyeccion Musical   \n3109   Find the schedule for The Cup Winner at the cl...   \n13484  Can you find me the game , Super Scription of ...   \n2948   will Dick Tracy e il gas misterioso start twen...   \n...                                                  ...   \n1418   book a spot at a restaurant within walking dis...   \n13379                    Find me the Martin Morning saga   \n4833            Rate A Handful of Darkness a value of 3    \n6101            weather forcast for current location now   \n7253   Give me the forecast for feb. eleventh, 2034 f...   \n\n                     intent  category  \n12271    SearchCreativeWork         6  \n11003             PlayMusic         5  \n3109   SearchScreeningEvent         1  \n13484    SearchCreativeWork         6  \n2948   SearchScreeningEvent         1  \n...                     ...       ...  \n1418         BookRestaurant         0  \n13379    SearchCreativeWork         6  \n4833               RateBook         2  \n6101             GetWeather         3  \n7253             GetWeather         3  \n\n[13784 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query</th>\n      <th>intent</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12271</th>\n      <td>find the painting Sleeping in Your Hand</td>\n      <td>SearchCreativeWork</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11003</th>\n      <td>Open Deezer and play Inyeccion Musical</td>\n      <td>PlayMusic</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3109</th>\n      <td>Find the schedule for The Cup Winner at the cl...</td>\n      <td>SearchScreeningEvent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13484</th>\n      <td>Can you find me the game , Super Scription of ...</td>\n      <td>SearchCreativeWork</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2948</th>\n      <td>will Dick Tracy e il gas misterioso start twen...</td>\n      <td>SearchScreeningEvent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1418</th>\n      <td>book a spot at a restaurant within walking dis...</td>\n      <td>BookRestaurant</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13379</th>\n      <td>Find me the Martin Morning saga</td>\n      <td>SearchCreativeWork</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4833</th>\n      <td>Rate A Handful of Darkness a value of 3</td>\n      <td>RateBook</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6101</th>\n      <td>weather forcast for current location now</td>\n      <td>GetWeather</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7253</th>\n      <td>Give me the forecast for feb. eleventh, 2034 f...</td>\n      <td>GetWeather</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>13784 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"load_data_obj.validation_data_frame.head().values","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:48.303305Z","iopub.execute_input":"2024-04-07T07:17:48.303678Z","iopub.status.idle":"2024-04-07T07:17:48.310444Z","shell.execute_reply.started":"2024-04-07T07:17:48.303625Z","shell.execute_reply":"2024-04-07T07:17:48.309485Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([['Play something from 2004 by Imogen Heap on spotify',\n        'PlayMusic', 5],\n       ['what are the times for The Gingerbread Man',\n        'SearchScreeningEvent', 1],\n       ['I want to book Tupelo Honey Cafe in New Jersey for five people.',\n        'BookRestaurant', 0],\n       ['Add jack white to my playlist This Is Shakira', 'AddToPlaylist',\n        4],\n       ['Rate the chronicle current 1 star', 'RateBook', 2]], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"load_data_obj.train_data_frame.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:48.460366Z","iopub.execute_input":"2024-04-07T07:17:48.460747Z","iopub.status.idle":"2024-04-07T07:17:48.471650Z","shell.execute_reply.started":"2024-04-07T07:17:48.460696Z","shell.execute_reply":"2024-04-07T07:17:48.470667Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                   query  \\\n12271            find the painting Sleeping in Your Hand   \n11003             Open Deezer and play Inyeccion Musical   \n3109   Find the schedule for The Cup Winner at the cl...   \n13484  Can you find me the game , Super Scription of ...   \n2948   will Dick Tracy e il gas misterioso start twen...   \n\n                     intent  category  \n12271    SearchCreativeWork         6  \n11003             PlayMusic         5  \n3109   SearchScreeningEvent         1  \n13484    SearchCreativeWork         6  \n2948   SearchScreeningEvent         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query</th>\n      <th>intent</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12271</th>\n      <td>find the painting Sleeping in Your Hand</td>\n      <td>SearchCreativeWork</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11003</th>\n      <td>Open Deezer and play Inyeccion Musical</td>\n      <td>PlayMusic</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3109</th>\n      <td>Find the schedule for The Cup Winner at the cl...</td>\n      <td>SearchScreeningEvent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13484</th>\n      <td>Can you find me the game , Super Scription of ...</td>\n      <td>SearchCreativeWork</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2948</th>\n      <td>will Dick Tracy e il gas misterioso start twen...</td>\n      <td>SearchScreeningEvent</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LSTM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Initialize the tokenizer\ntokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(load_data_obj.train_data_frame['query'])\n\n# Convert text to sequence of integers\ntrain_sequences = tokenizer.texts_to_sequences(load_data_obj.train_data_frame['query'])\nvalidation_sequences = tokenizer.texts_to_sequences(load_data_obj.validation_data_frame['query'])\n\n# Pad sequences to ensure uniform length\nmax_length = max([len(x) for x in train_sequences])\ntrain_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\nvalidation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding='post')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:48.950483Z","iopub.execute_input":"2024-04-07T07:17:48.950867Z","iopub.status.idle":"2024-04-07T07:17:49.606748Z","shell.execute_reply.started":"2024-04-07T07:17:48.950809Z","shell.execute_reply":"2024-04-07T07:17:49.605978Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.utils import to_categorical\n\n# Convert labels to one-hot encoding\ntrain_labels = to_categorical(load_data_obj.train_data_frame['category'])\nvalidation_labels = to_categorical(load_data_obj.validation_data_frame['category'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:49.608482Z","iopub.execute_input":"2024-04-07T07:17:49.608838Z","iopub.status.idle":"2024-04-07T07:17:49.614665Z","shell.execute_reply.started":"2024-04-07T07:17:49.608784Z","shell.execute_reply":"2024-04-07T07:17:49.613678Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n\n# Assuming max_length is defined here, e.g., max_length = max([len(x) for x in train_sequences])\nmax_length = max([len(x) for x in train_sequences])\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=5000, output_dim=32, input_length=max_length))  # Adjusted output_dim\nmodel.add(Bidirectional(LSTM(128, return_sequences=False)))  # Increased LSTM units and added Bidirectional layer\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3))  # Adjusted dropout rate\nmodel.add(Dense(len(train_labels[0]), activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:49.615985Z","iopub.execute_input":"2024-04-07T07:17:49.616406Z","iopub.status.idle":"2024-04-07T07:17:52.924278Z","shell.execute_reply.started":"2024-04-07T07:17:49.616345Z","shell.execute_reply":"2024-04-07T07:17:52.923481Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 35, 32)            160000    \n_________________________________________________________________\nbidirectional (Bidirectional (None, 256)               164864    \n_________________________________________________________________\ndense (Dense)                (None, 64)                16448     \n_________________________________________________________________\ndropout (Dropout)            (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 455       \n=================================================================\nTotal params: 341,767\nTrainable params: 341,767\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(train_padded, train_labels, epochs=10, validation_data=(validation_padded, validation_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:17:52.927322Z","iopub.execute_input":"2024-04-07T07:17:52.927633Z","iopub.status.idle":"2024-04-07T07:18:34.491732Z","shell.execute_reply.started":"2024-04-07T07:17:52.927580Z","shell.execute_reply":"2024-04-07T07:18:34.490915Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train on 13784 samples, validate on 700 samples\nEpoch 1/10\n13784/13784 [==============================] - 9s 664us/sample - loss: 0.5113 - accuracy: 0.8249 - val_loss: 0.0794 - val_accuracy: 0.9743\nEpoch 2/10\n13784/13784 [==============================] - 4s 259us/sample - loss: 0.0565 - accuracy: 0.9836 - val_loss: 0.0587 - val_accuracy: 0.9843\nEpoch 3/10\n13784/13784 [==============================] - 4s 257us/sample - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.0650 - val_accuracy: 0.9786\nEpoch 4/10\n13784/13784 [==============================] - 4s 257us/sample - loss: 0.0246 - accuracy: 0.9941 - val_loss: 0.0675 - val_accuracy: 0.9786\nEpoch 5/10\n13784/13784 [==============================] - 4s 259us/sample - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0683 - val_accuracy: 0.9786\nEpoch 6/10\n13784/13784 [==============================] - 4s 259us/sample - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0961 - val_accuracy: 0.9771\nEpoch 7/10\n13784/13784 [==============================] - 4s 260us/sample - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.1119 - val_accuracy: 0.9729\nEpoch 8/10\n13784/13784 [==============================] - 4s 263us/sample - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0902 - val_accuracy: 0.9729\nEpoch 9/10\n13784/13784 [==============================] - 4s 260us/sample - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.0812 - val_accuracy: 0.9786\nEpoch 10/10\n13784/13784 [==============================] - 4s 273us/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0959 - val_accuracy: 0.9814\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(validation_padded, validation_labels)\nprint(f'Validation loss: {loss}, Validation accuracy: {accuracy}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:34.494742Z","iopub.execute_input":"2024-04-07T07:18:34.495061Z","iopub.status.idle":"2024-04-07T07:18:34.606404Z","shell.execute_reply.started":"2024-04-07T07:18:34.495011Z","shell.execute_reply":"2024-04-07T07:18:34.605658Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"700/700 [==============================] - 0s 114us/sample - loss: 0.0959 - accuracy: 0.9814\nValidation loss: 0.09589042356121354, Validation accuracy: 0.9814285635948181\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Create a DataFrame for results\nresults_df = pd.DataFrame(columns=['model_name', 'validation_accuracy'])\n\n# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'LSTM', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:34.607962Z","iopub.execute_input":"2024-04-07T07:18:34.608286Z","iopub.status.idle":"2024-04-07T07:18:34.623234Z","shell.execute_reply.started":"2024-04-07T07:18:34.608235Z","shell.execute_reply":"2024-04-07T07:18:34.622391Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"  model_name  validation_accuracy\n0       LSTM             0.981429\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## RANDOM FOREST\n","metadata":{}},{"cell_type":"code","source":"train_data_frame=load_data_obj.train_data_frame\nvalidation_data_frame=load_data_obj.validation_data_frame\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\n# TF-IDF Vectorization\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\ntrain_tfidf = tfidf_vectorizer.fit_transform(train_data_frame['query'])\nvalidation_tfidf = tfidf_vectorizer.transform(validation_data_frame['query'])\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ntrain_labels_encoded = label_encoder.fit_transform(train_data_frame['category'])\nvalidation_labels_encoded = label_encoder.transform(validation_data_frame['category'])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:34.624447Z","iopub.execute_input":"2024-04-07T07:18:34.624770Z","iopub.status.idle":"2024-04-07T07:18:34.925739Z","shell.execute_reply.started":"2024-04-07T07:18:34.624727Z","shell.execute_reply":"2024-04-07T07:18:34.924882Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Initialize the Random Forest Classifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_classifier.fit(train_tfidf, train_labels_encoded)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:34.926946Z","iopub.execute_input":"2024-04-07T07:18:34.927246Z","iopub.status.idle":"2024-04-07T07:18:41.111136Z","shell.execute_reply.started":"2024-04-07T07:18:34.927204Z","shell.execute_reply":"2024-04-07T07:18:41.110226Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                       warm_start=False)"},"metadata":{}}]},{"cell_type":"code","source":"# Predict on validation set\nvalidation_predictions = rf_classifier.predict(validation_tfidf)\n\n# Calculate accuracy\nvalidation_accuracy = accuracy_score(validation_labels_encoded, validation_predictions)\nprint(f'Validation Accuracy of Random Forest: {validation_accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:41.112735Z","iopub.execute_input":"2024-04-07T07:18:41.113136Z","iopub.status.idle":"2024-04-07T07:18:41.153271Z","shell.execute_reply.started":"2024-04-07T07:18:41.113076Z","shell.execute_reply":"2024-04-07T07:18:41.152527Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Validation Accuracy of Random Forest: 97.43%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'Random Forest', 'validation_accuracy': validation_accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:41.154349Z","iopub.execute_input":"2024-04-07T07:18:41.154676Z","iopub.status.idle":"2024-04-07T07:18:41.164621Z","shell.execute_reply.started":"2024-04-07T07:18:41.154621Z","shell.execute_reply":"2024-04-07T07:18:41.163688Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"      model_name  validation_accuracy\n0           LSTM             0.981429\n1  Random Forest             0.974286\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Initialize the Logistic Regression Classifier\nlog_reg_classifier = LogisticRegression(max_iter=1000)  # Increase max_iter if the model doesn't converge\n\n# Train the model\nlog_reg_classifier.fit(train_tfidf, train_labels_encoded)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:41.165980Z","iopub.execute_input":"2024-04-07T07:18:41.166398Z","iopub.status.idle":"2024-04-07T07:18:42.555039Z","shell.execute_reply.started":"2024-04-07T07:18:41.166338Z","shell.execute_reply":"2024-04-07T07:18:42.554211Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"},"metadata":{}}]},{"cell_type":"code","source":"# Predict on validation set\nvalidation_predictions = log_reg_classifier.predict(validation_tfidf)\n\n# Calculate accuracy\nvalidation_accuracy = accuracy_score(validation_labels_encoded, validation_predictions)\nprint(f'Validation Accuracy of Logistic Regression: {validation_accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:42.556299Z","iopub.execute_input":"2024-04-07T07:18:42.556818Z","iopub.status.idle":"2024-04-07T07:18:42.563433Z","shell.execute_reply.started":"2024-04-07T07:18:42.556773Z","shell.execute_reply":"2024-04-07T07:18:42.562579Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Validation Accuracy of Logistic Regression: 98.29%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'Logistic Regression', 'validation_accuracy': validation_accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:42.564826Z","iopub.execute_input":"2024-04-07T07:18:42.565413Z","iopub.status.idle":"2024-04-07T07:18:42.577713Z","shell.execute_reply.started":"2024-04-07T07:18:42.565319Z","shell.execute_reply":"2024-04-07T07:18:42.576924Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GRU","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# Initialize the model\nmodel = Sequential()\n\n# Add an Embedding layer\nmodel.add(Embedding(input_dim=5000, output_dim=16, input_length=max_length))\n\n# First GRU layer with Dropout regularization\nmodel.add(GRU(units=50, return_sequences=True, activation='tanh'))\nmodel.add(Dropout(0.2))\n\n# Second GRU layer\nmodel.add(GRU(units=50, return_sequences=True, activation='tanh'))\nmodel.add(Dropout(0.2))\n\n# Third GRU layer\nmodel.add(GRU(units=50, return_sequences=True, activation='tanh'))\nmodel.add(Dropout(0.2))\n\n# Fourth GRU layer\nmodel.add(GRU(units=50, activation='tanh'))\nmodel.add(Dropout(0.2))\n\n# Output layer for classification (units = number of classes, softmax activation)\nmodel.add(Dense(units=len(train_labels[0]), activation='softmax'))  # Adjust the units based on the number of classes\n\n# Compile the model for classification\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:42.579125Z","iopub.execute_input":"2024-04-07T07:18:42.579635Z","iopub.status.idle":"2024-04-07T07:18:43.379455Z","shell.execute_reply.started":"2024-04-07T07:18:42.579583Z","shell.execute_reply":"2024-04-07T07:18:43.378411Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 35, 16)            80000     \n_________________________________________________________________\ngru (GRU)                    (None, 35, 50)            10200     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 35, 50)            0         \n_________________________________________________________________\ngru_1 (GRU)                  (None, 35, 50)            15300     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 35, 50)            0         \n_________________________________________________________________\ngru_2 (GRU)                  (None, 35, 50)            15300     \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 35, 50)            0         \n_________________________________________________________________\ngru_3 (GRU)                  (None, 50)                15300     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 357       \n=================================================================\nTotal params: 136,457\nTrainable params: 136,457\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_padded, train_labels, epochs=10, validation_data=(validation_padded, validation_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:18:43.381582Z","iopub.execute_input":"2024-04-07T07:18:43.381983Z","iopub.status.idle":"2024-04-07T07:19:42.921256Z","shell.execute_reply.started":"2024-04-07T07:18:43.381919Z","shell.execute_reply":"2024-04-07T07:19:42.920316Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Train on 13784 samples, validate on 700 samples\nEpoch 1/10\n13784/13784 [==============================] - 10s 760us/sample - loss: 1.9478 - accuracy: 0.1391 - val_loss: 1.9467 - val_accuracy: 0.1429\nEpoch 2/10\n13784/13784 [==============================] - 5s 391us/sample - loss: 1.8734 - accuracy: 0.1669 - val_loss: 1.4000 - val_accuracy: 0.4100\nEpoch 3/10\n13784/13784 [==============================] - 5s 398us/sample - loss: 0.5268 - accuracy: 0.7994 - val_loss: 0.3140 - val_accuracy: 0.9143\nEpoch 4/10\n13784/13784 [==============================] - 5s 394us/sample - loss: 0.1833 - accuracy: 0.9509 - val_loss: 0.2405 - val_accuracy: 0.9386\nEpoch 5/10\n13784/13784 [==============================] - 5s 394us/sample - loss: 0.1194 - accuracy: 0.9697 - val_loss: 0.1859 - val_accuracy: 0.9529\nEpoch 6/10\n13784/13784 [==============================] - 5s 392us/sample - loss: 0.0763 - accuracy: 0.9808 - val_loss: 0.1908 - val_accuracy: 0.9529\nEpoch 7/10\n13784/13784 [==============================] - 5s 396us/sample - loss: 0.0534 - accuracy: 0.9880 - val_loss: 0.1673 - val_accuracy: 0.9643\nEpoch 8/10\n13784/13784 [==============================] - 5s 392us/sample - loss: 0.0499 - accuracy: 0.9884 - val_loss: 0.2007 - val_accuracy: 0.9600\nEpoch 9/10\n13784/13784 [==============================] - 6s 404us/sample - loss: 0.0412 - accuracy: 0.9911 - val_loss: 0.1385 - val_accuracy: 0.9714\nEpoch 10/10\n13784/13784 [==============================] - 5s 395us/sample - loss: 0.0435 - accuracy: 0.9896 - val_loss: 0.1290 - val_accuracy: 0.9700\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(validation_padded, validation_labels)\nprint(f'Validation loss: {loss}, Validation accuracy: {accuracy}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:19:42.925018Z","iopub.execute_input":"2024-04-07T07:19:42.925333Z","iopub.status.idle":"2024-04-07T07:19:43.064019Z","shell.execute_reply.started":"2024-04-07T07:19:42.925282Z","shell.execute_reply":"2024-04-07T07:19:43.062948Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"700/700 [==============================] - 0s 151us/sample - loss: 0.1290 - accuracy: 0.9700\nValidation loss: 0.12895991353052003, Validation accuracy: 0.9700000286102295\n","output_type":"stream"}]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'GRU', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:19:43.065541Z","iopub.execute_input":"2024-04-07T07:19:43.065901Z","iopub.status.idle":"2024-04-07T07:19:43.076785Z","shell.execute_reply.started":"2024-04-07T07:19:43.065853Z","shell.execute_reply":"2024-04-07T07:19:43.075739Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## RNN ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Embedding, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# Initialize the model\nmodel = Sequential()\n\n# Add an Embedding layer\nmodel.add(Embedding(input_dim=5000, output_dim=16, input_length=max_length))\n\n# Add a SimpleRNN layer\nmodel.add(SimpleRNN(units=64, return_sequences=True))\nmodel.add(Dropout(0.2))\n\n# Add another SimpleRNN layer\nmodel.add(SimpleRNN(units=64))\nmodel.add(Dropout(0.2))\n\n# Add the output Dense layer with softmax activation for multi-class classification\nmodel.add(Dense(units=len(train_labels[0]), activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Display the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:19:43.078075Z","iopub.execute_input":"2024-04-07T07:19:43.078390Z","iopub.status.idle":"2024-04-07T07:19:43.273985Z","shell.execute_reply.started":"2024-04-07T07:19:43.078346Z","shell.execute_reply":"2024-04-07T07:19:43.273146Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 35, 16)            80000     \n_________________________________________________________________\nsimple_rnn (SimpleRNN)       (None, 35, 64)            5184      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 35, 64)            0         \n_________________________________________________________________\nsimple_rnn_1 (SimpleRNN)     (None, 64)                8256      \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 7)                 455       \n=================================================================\nTotal params: 93,895\nTrainable params: 93,895\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_padded, train_labels, epochs=10, validation_data=(validation_padded, validation_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:19:43.275200Z","iopub.execute_input":"2024-04-07T07:19:43.275502Z","iopub.status.idle":"2024-04-07T07:22:02.619627Z","shell.execute_reply.started":"2024-04-07T07:19:43.275453Z","shell.execute_reply":"2024-04-07T07:22:02.618682Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Train on 13784 samples, validate on 700 samples\nEpoch 1/10\n13784/13784 [==============================] - 16s 1ms/sample - loss: 0.4116 - accuracy: 0.8693 - val_loss: 0.1726 - val_accuracy: 0.9514\nEpoch 2/10\n13784/13784 [==============================] - 14s 1ms/sample - loss: 0.1275 - accuracy: 0.9642 - val_loss: 0.1749 - val_accuracy: 0.9471\nEpoch 3/10\n13784/13784 [==============================] - 14s 992us/sample - loss: 0.0850 - accuracy: 0.9769 - val_loss: 0.2253 - val_accuracy: 0.9400\nEpoch 4/10\n13784/13784 [==============================] - 14s 997us/sample - loss: 0.0687 - accuracy: 0.9808 - val_loss: 0.2269 - val_accuracy: 0.9486\nEpoch 5/10\n13784/13784 [==============================] - 14s 991us/sample - loss: 0.0452 - accuracy: 0.9873 - val_loss: 0.1521 - val_accuracy: 0.9614\nEpoch 6/10\n13784/13784 [==============================] - 14s 990us/sample - loss: 0.0580 - accuracy: 0.9849 - val_loss: 0.1364 - val_accuracy: 0.9700\nEpoch 7/10\n13784/13784 [==============================] - 14s 1ms/sample - loss: 0.0728 - accuracy: 0.9801 - val_loss: 0.1349 - val_accuracy: 0.9700\nEpoch 8/10\n13784/13784 [==============================] - 14s 1ms/sample - loss: 0.0394 - accuracy: 0.9890 - val_loss: 0.1619 - val_accuracy: 0.9686\nEpoch 9/10\n13784/13784 [==============================] - 14s 983us/sample - loss: 0.0419 - accuracy: 0.9893 - val_loss: 0.2029 - val_accuracy: 0.9557\nEpoch 10/10\n13784/13784 [==============================] - 13s 977us/sample - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.1652 - val_accuracy: 0.9586\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(validation_padded, validation_labels)\nprint(f'Validation loss: {loss}, Validation accuracy: {accuracy}')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:22:02.621328Z","iopub.execute_input":"2024-04-07T07:22:02.621735Z","iopub.status.idle":"2024-04-07T07:22:02.790920Z","shell.execute_reply.started":"2024-04-07T07:22:02.621674Z","shell.execute_reply":"2024-04-07T07:22:02.790032Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"700/700 [==============================] - 0s 197us/sample - loss: 0.1652 - accuracy: 0.9586\nValidation loss: 0.1652447593957186, Validation accuracy: 0.9585714340209961\n","output_type":"stream"}]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'RNN', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:22:02.792035Z","iopub.execute_input":"2024-04-07T07:22:02.792317Z","iopub.status.idle":"2024-04-07T07:22:02.802686Z","shell.execute_reply.started":"2024-04-07T07:22:02.792277Z","shell.execute_reply":"2024-04-07T07:22:02.801641Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n4                  RNN             0.958571\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom transformers import TFBertModel, BertTokenizer\n\n\n# Load the tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = TFBertModel.from_pretrained('bert-base-uncased')\n\n# Load and preprocess the data\ndata_train = train_data_frame[['query', 'intent']]\ndata_train['category'] = pd.Categorical(data_train['intent'])\ndata_train['intent'] = data_train['category'].cat.codes\n\n# Load and preprocess the data\ndata_test = validation_data_frame[['query', 'intent']]\ndata_test['category'] = pd.Categorical(data_test['intent'])\ndata_test['intent'] = data_test['category'].cat.codes\n\n\n\n# Extract the training and testing texts and labels\ntrain_texts = data_train['query'].tolist()\ntrain_labels = data_train['intent'].tolist()\ntest_texts = data_test['query'].tolist()\ntest_labels = data_test['intent'].tolist()\n\nmax_length = 128  # Adjust based on your dataset or model's max length\n\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\ntest_encodings = tokenizer.batch_encode_plus(\n    test_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\n\n\n# Convert the labels to one-hot encoding\nnum_labels = len(data_train['category'].cat.categories)\ntrain_labels_encoded = tf.one_hot(train_labels, num_labels)\ntest_labels_encoded = tf.one_hot(test_labels, num_labels)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels_encoded))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels_encoded))\n\n# Define the model architecture\ninput_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\noutput = model(input_ids, attention_mask=attention_mask)[0]\noutput = tf.keras.layers.Dense(num_labels, activation='softmax')(output[:, 0, :])  # Pooling the output\nmodel = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n# Compile and train the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\nmetrics = ['accuracy']\n\n\n\n# Use smaller batch size\nbatch_size = 20\n\n\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.fit(train_dataset.batch(batch_size), epochs=10)\n\n# Evaluate the model\nmodel.evaluate(test_dataset.batch(batch_size))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T07:22:02.804397Z","iopub.execute_input":"2024-04-07T07:22:02.804849Z","iopub.status.idle":"2024-04-07T08:00:53.346573Z","shell.execute_reply.started":"2024-04-07T07:22:02.804792Z","shell.execute_reply":"2024-04-07T08:00:53.345646Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c8c8809c524586844d5f45c3eeb68b"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0393250f42c9435a8a744814e14b5abb"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1a149760e24b419028d32f00787f98"}},"metadata":{}},{"name":"stdout","text":"\nTrain for 690 steps\nEpoch 1/10\n690/690 [==============================] - 243s 353ms/step - loss: 1.2315 - accuracy: 0.9463\nEpoch 2/10\n690/690 [==============================] - 228s 330ms/step - loss: 1.1775 - accuracy: 0.9888\nEpoch 3/10\n690/690 [==============================] - 228s 330ms/step - loss: 1.1755 - accuracy: 0.9904\nEpoch 4/10\n690/690 [==============================] - 227s 330ms/step - loss: 1.1743 - accuracy: 0.9913\nEpoch 5/10\n690/690 [==============================] - 227s 330ms/step - loss: 1.1735 - accuracy: 0.9920\nEpoch 6/10\n690/690 [==============================] - 227s 330ms/step - loss: 1.1715 - accuracy: 0.9941\nEpoch 7/10\n690/690 [==============================] - 228s 330ms/step - loss: 1.1733 - accuracy: 0.9923\nEpoch 8/10\n690/690 [==============================] - 228s 330ms/step - loss: 1.1726 - accuracy: 0.9930\nEpoch 9/10\n690/690 [==============================] - 228s 330ms/step - loss: 1.1720 - accuracy: 0.9935\nEpoch 10/10\n690/690 [==============================] - 228s 330ms/step - loss: 1.1707 - accuracy: 0.9948\n35/35 [==============================] - 7s 205ms/step - loss: 1.1784 - accuracy: 0.9871\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[1.1784067119870867, 0.98714286]"},"metadata":{}}]},{"cell_type":"code","source":"evaluation_results = model.evaluate(test_dataset.batch(batch_size))\naccuracy = evaluation_results[1]  # Assuming accuracy is the second metric in the metrics list\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:00:53.347904Z","iopub.execute_input":"2024-04-07T08:00:53.348190Z","iopub.status.idle":"2024-04-07T08:00:57.783893Z","shell.execute_reply.started":"2024-04-07T08:00:53.348148Z","shell.execute_reply":"2024-04-07T08:00:57.783084Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"35/35 [==============================] - 4s 126ms/step - loss: 1.1784 - accuracy: 0.9871\n","output_type":"stream"}]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'BERT', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:00:57.785423Z","iopub.execute_input":"2024-04-07T08:00:57.785856Z","iopub.status.idle":"2024-04-07T08:00:57.797058Z","shell.execute_reply.started":"2024-04-07T08:00:57.785795Z","shell.execute_reply":"2024-04-07T08:00:57.796086Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n4                  RNN             0.958571\n5                 BERT             0.987143\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROBERTA\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom transformers import TFRobertaModel, RobertaTokenizer\n\n#Load the tokenizer and model\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nmodel = TFRobertaModel.from_pretrained('roberta-base')\n\n\n\n# Load and preprocess the data\ndata_train = train_data_frame[['query', 'intent']]\ndata_train['category'] = pd.Categorical(data_train['intent'])\ndata_train['intent'] = data_train['category'].cat.codes\n\n# Load and preprocess the data\ndata_test = validation_data_frame[['query', 'intent']]\ndata_test['category'] = pd.Categorical(data_test['intent'])\ndata_test['intent'] = data_test['category'].cat.codes\n\n\n\n# Extract the training and testing texts and labels\ntrain_texts = data_train['query'].tolist()\ntrain_labels = data_train['intent'].tolist()\ntest_texts = data_test['query'].tolist()\ntest_labels = data_test['intent'].tolist()\n\nmax_length = 128  # Adjust based on your dataset or model's max length\n\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\ntest_encodings = tokenizer.batch_encode_plus(\n    test_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\n\n\n# Convert the labels to one-hot encoding\nnum_labels = len(data_train['category'].cat.categories)\ntrain_labels_encoded = tf.one_hot(train_labels, num_labels)\ntest_labels_encoded = tf.one_hot(test_labels, num_labels)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels_encoded))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels_encoded))\n\n#Define the model architecture\ninput_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\noutput = model(input_ids, attention_mask=attention_mask)[0]\noutput = tf.keras.layers.Dense(num_labels, activation='softmax')(output[:, 0, :]) # Pooling the output\nmodel = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n#Compile and train the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\nmetrics = ['accuracy']\n\n\n# Use smaller batch size\nbatch_size = 20\n\n\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.fit(train_dataset.batch(batch_size), epochs=10)\n\n# Evaluate the model\n\nevaluation_results = model.evaluate(test_dataset.batch(batch_size))\naccuracy = evaluation_results[1]  # Assuming accuracy is the second metric in the metrics list","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:00:57.798494Z","iopub.execute_input":"2024-04-07T08:00:57.798952Z","iopub.status.idle":"2024-04-07T08:40:13.350661Z","shell.execute_reply.started":"2024-04-07T08:00:57.798886Z","shell.execute_reply":"2024-04-07T08:40:13.349814Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6354f5127cf149a9a44adb542659e5c6"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e37afc4e3934a619285834bbe930066"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5debbc2a497e4a669e76e0206250cc6e"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"818c418d62a548e19ca2bb63e9f7f7ee"}},"metadata":{}},{"name":"stdout","text":"\nTrain for 690 steps\nEpoch 1/10\n690/690 [==============================] - 247s 358ms/step - loss: 1.2401 - accuracy: 0.9301\nEpoch 2/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1826 - accuracy: 0.9827\nEpoch 3/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1777 - accuracy: 0.9880\nEpoch 4/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1792 - accuracy: 0.9864\nEpoch 5/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1768 - accuracy: 0.9888\nEpoch 6/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1757 - accuracy: 0.9897\nEpoch 7/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1794 - accuracy: 0.9861\nEpoch 8/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1761 - accuracy: 0.9893\nEpoch 9/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1753 - accuracy: 0.9901\nEpoch 10/10\n690/690 [==============================] - 230s 334ms/step - loss: 1.1756 - accuracy: 0.9898\n35/35 [==============================] - 7s 212ms/step - loss: 1.1758 - accuracy: 0.9900\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'Roberta', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:40:13.352190Z","iopub.execute_input":"2024-04-07T08:40:13.352625Z","iopub.status.idle":"2024-04-07T08:40:13.363816Z","shell.execute_reply.started":"2024-04-07T08:40:13.352534Z","shell.execute_reply":"2024-04-07T08:40:13.362893Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n4                  RNN             0.958571\n5                 BERT             0.987143\n6              Roberta             0.990000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XLnet ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom transformers import TFXLNetModel, XLNetTokenizer\n\n# Load the tokenizer and model\ntokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\nmodel = TFXLNetModel.from_pretrained('xlnet-base-cased')\n\n\n\n\n# Load and preprocess the data\ndata_train = train_data_frame[['query', 'intent']]\ndata_train['category'] = pd.Categorical(data_train['intent'])\ndata_train['intent'] = data_train['category'].cat.codes\n\n# Load and preprocess the data\ndata_test = validation_data_frame[['query', 'intent']]\ndata_test['category'] = pd.Categorical(data_test['intent'])\ndata_test['intent'] = data_test['category'].cat.codes\n\n\n\n# Extract the training and testing texts and labels\ntrain_texts = data_train['query'].tolist()\ntrain_labels = data_train['intent'].tolist()\ntest_texts = data_test['query'].tolist()\ntest_labels = data_test['intent'].tolist()\n\nmax_length = 128  # Adjust based on your dataset or model's max length\n\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\ntest_encodings = tokenizer.batch_encode_plus(\n    test_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\n\n\n# Convert the labels to one-hot encoding\nnum_labels = len(data_train['category'].cat.categories)\ntrain_labels_encoded = tf.one_hot(train_labels, num_labels)\ntest_labels_encoded = tf.one_hot(test_labels, num_labels)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels_encoded))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels_encoded))\n\n#Define the model architecture\ninput_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\noutput = model(input_ids, attention_mask=attention_mask)[0]\noutput = tf.keras.layers.Dense(num_labels, activation='softmax')(output[:, 0, :]) # Pooling the output\nmodel = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n#Compile and train the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\nmetrics = ['accuracy']\n\n\n# Use smaller batch size\nbatch_size = 20\n\n\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.fit(train_dataset.batch(batch_size), epochs=10)\n\n# Evaluate the model\n\nevaluation_results = model.evaluate(test_dataset.batch(batch_size))\naccuracy = evaluation_results[1]  # Assuming accuracy is the second metric in the metrics list","metadata":{"execution":{"iopub.status.busy":"2024-04-07T08:40:13.365443Z","iopub.execute_input":"2024-04-07T08:40:13.365884Z","iopub.status.idle":"2024-04-07T09:29:37.080435Z","shell.execute_reply.started":"2024-04-07T08:40:13.365820Z","shell.execute_reply":"2024-04-07T09:29:37.079658Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"256cf51c0994404a9a17a687c4f1e1c8"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfd77a6d1182434484df8d01d248bc64"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=565485600.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"162a2f52572444209b0c13e0cfd4d0c8"}},"metadata":{}},{"name":"stdout","text":"\nTrain for 690 steps\nEpoch 1/10\n690/690 [==============================] - 305s 442ms/step - loss: 1.4381 - accuracy: 0.7217\nEpoch 2/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1938 - accuracy: 0.9717\nEpoch 3/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1863 - accuracy: 0.9794\nEpoch 4/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1846 - accuracy: 0.9808\nEpoch 5/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1813 - accuracy: 0.9841\nEpoch 6/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1816 - accuracy: 0.9835\nEpoch 7/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1815 - accuracy: 0.9840\nEpoch 8/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1810 - accuracy: 0.9845\nEpoch 9/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1816 - accuracy: 0.9836\nEpoch 10/10\n690/690 [==============================] - 291s 422ms/step - loss: 1.1785 - accuracy: 0.9869\n35/35 [==============================] - 7s 206ms/step - loss: 1.1826 - accuracy: 0.9829\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'XLnet', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:29:37.081837Z","iopub.execute_input":"2024-04-07T09:29:37.082114Z","iopub.status.idle":"2024-04-07T09:29:37.093036Z","shell.execute_reply.started":"2024-04-07T09:29:37.082074Z","shell.execute_reply":"2024-04-07T09:29:37.092229Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n4                  RNN             0.958571\n5                 BERT             0.987143\n6              Roberta             0.990000\n7                XLnet             0.982857\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## DistilBert\n","metadata":{}},{"cell_type":"code","source":"from transformers import TFDistilBertModel, DistilBertTokenizer\n\n#Load the tokenizer and model\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n\n\n\n\n# Load and preprocess the data\ndata_train = train_data_frame[['query', 'intent']]\ndata_train['category'] = pd.Categorical(data_train['intent'])\ndata_train['intent'] = data_train['category'].cat.codes\n\n# Load and preprocess the data\ndata_test = validation_data_frame[['query', 'intent']]\ndata_test['category'] = pd.Categorical(data_test['intent'])\ndata_test['intent'] = data_test['category'].cat.codes\n\n\n\n# Extract the training and testing texts and labels\ntrain_texts = data_train['query'].tolist()\ntrain_labels = data_train['intent'].tolist()\ntest_texts = data_test['query'].tolist()\ntest_labels = data_test['intent'].tolist()\n\nmax_length = 128  # Adjust based on your dataset or model's max length\n\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\ntest_encodings = tokenizer.batch_encode_plus(\n    test_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\n\n\n# Convert the labels to one-hot encoding\nnum_labels = len(data_train['category'].cat.categories)\ntrain_labels_encoded = tf.one_hot(train_labels, num_labels)\ntest_labels_encoded = tf.one_hot(test_labels, num_labels)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels_encoded))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels_encoded))\n\n#Define the model architecture\ninput_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\noutput = model(input_ids, attention_mask=attention_mask)[0]\noutput = tf.keras.layers.Dense(num_labels, activation='softmax')(output[:, 0, :]) # Pooling the output\nmodel = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n#Compile and train the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\nmetrics = ['accuracy']\n\n\n# Use smaller batch size\nbatch_size = 20\n\n\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.fit(train_dataset.batch(batch_size), epochs=10)\n\n# Evaluate the model\n\nevaluation_results = model.evaluate(test_dataset.batch(batch_size))\naccuracy = evaluation_results[1]  # Assuming accuracy is the second metric in the metrics list","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:29:37.094543Z","iopub.execute_input":"2024-04-07T09:29:37.094931Z","iopub.status.idle":"2024-04-07T09:49:28.803151Z","shell.execute_reply.started":"2024-04-07T09:29:37.094876Z","shell.execute_reply":"2024-04-07T09:49:28.802269Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"302f6f3bcc5f41c5b10eb97a909d0547"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=363423424.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ed0f0c40d6439ba41b95ff83dd2e51"}},"metadata":{}},{"name":"stdout","text":"\nTrain for 690 steps\nEpoch 1/10\n690/690 [==============================] - 124s 180ms/step - loss: 1.2452 - accuracy: 0.9308\nEpoch 2/10\n690/690 [==============================] - 116s 169ms/step - loss: 1.1784 - accuracy: 0.9877\nEpoch 3/10\n690/690 [==============================] - 116s 169ms/step - loss: 1.1759 - accuracy: 0.9899\nEpoch 4/10\n690/690 [==============================] - 116s 168ms/step - loss: 1.1733 - accuracy: 0.9923\nEpoch 5/10\n690/690 [==============================] - 116s 168ms/step - loss: 1.1734 - accuracy: 0.9922\nEpoch 6/10\n690/690 [==============================] - 116s 168ms/step - loss: 1.1721 - accuracy: 0.9934\nEpoch 7/10\n690/690 [==============================] - 116s 168ms/step - loss: 1.1721 - accuracy: 0.9933\nEpoch 8/10\n690/690 [==============================] - 116s 168ms/step - loss: 1.1714 - accuracy: 0.9941\nEpoch 9/10\n690/690 [==============================] - 116s 168ms/step - loss: 1.1715 - accuracy: 0.9940\nEpoch 10/10\n690/690 [==============================] - 116s 168ms/step - loss: 1.1705 - accuracy: 0.9950\n35/35 [==============================] - 4s 100ms/step - loss: 1.1754 - accuracy: 0.9900\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'DistilBert', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T09:49:28.804476Z","iopub.execute_input":"2024-04-07T09:49:28.804770Z","iopub.status.idle":"2024-04-07T09:49:28.815510Z","shell.execute_reply.started":"2024-04-07T09:49:28.804729Z","shell.execute_reply":"2024-04-07T09:49:28.814610Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n4                  RNN             0.958571\n5                 BERT             0.987143\n6              Roberta             0.990000\n7                XLnet             0.982857\n8           DistilBert             0.990000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T10:06:23.897010Z","iopub.execute_input":"2024-04-07T10:06:23.897391Z","iopub.status.idle":"2024-04-07T10:06:23.904862Z","shell.execute_reply.started":"2024-04-07T10:06:23.897330Z","shell.execute_reply":"2024-04-07T10:06:23.903845Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n4                  RNN             0.958571\n5                 BERT             0.987143\n6              Roberta             0.990000\n7                XLnet             0.982857\n8           DistilBert             0.990000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Albert","metadata":{}},{"cell_type":"code","source":"from transformers import TFAlbertModel, AlbertTokenizer\n\ntokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\nmodel = TFAlbertModel.from_pretrained('albert-base-v2')\n\n\n# Load and preprocess the data\ndata_train = train_data_frame[['query', 'intent']]\ndata_train['category'] = pd.Categorical(data_train['intent'])\ndata_train['intent'] = data_train['category'].cat.codes\n\n# Load and preprocess the data\ndata_test = validation_data_frame[['query', 'intent']]\ndata_test['category'] = pd.Categorical(data_test['intent'])\ndata_test['intent'] = data_test['category'].cat.codes\n\n\n\n# Extract the training and testing texts and labels\ntrain_texts = data_train['query'].tolist()\ntrain_labels = data_train['intent'].tolist()\ntest_texts = data_test['query'].tolist()\ntest_labels = data_test['intent'].tolist()\n\nmax_length = 128  # Adjust based on your dataset or model's max length\n\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\ntest_encodings = tokenizer.batch_encode_plus(\n    test_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\n\n\n# Convert the labels to one-hot encoding\nnum_labels = len(data_train['category'].cat.categories)\ntrain_labels_encoded = tf.one_hot(train_labels, num_labels)\ntest_labels_encoded = tf.one_hot(test_labels, num_labels)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels_encoded))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels_encoded))\n\n#Define the model architecture\ninput_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\noutput = model(input_ids, attention_mask=attention_mask)[0]\noutput = tf.keras.layers.Dense(num_labels, activation='softmax')(output[:, 0, :]) # Pooling the output\nmodel = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n#Compile and train the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\nmetrics = ['accuracy']\n\n\n# Use smaller batch size\nbatch_size = 20\n\n\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.fit(train_dataset.batch(batch_size), epochs=10)\n\n# Evaluate the model\n\nevaluation_results = model.evaluate(test_dataset.batch(batch_size))\naccuracy = evaluation_results[1]  # Assuming accuracy is the second metric in the metrics list","metadata":{"execution":{"iopub.status.busy":"2024-04-07T10:10:44.949494Z","iopub.execute_input":"2024-04-07T10:10:44.949872Z","iopub.status.idle":"2024-04-07T10:47:38.842123Z","shell.execute_reply.started":"2024-04-07T10:10:44.949835Z","shell.execute_reply":"2024-04-07T10:47:38.841323Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d6bbba36a9142d7b5b2342f30441c48"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae5b981cc49948849388d8e7c1b506cc"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=63048440.0, style=ProgressStyle(descrip…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e483211b9d64378bb8f5afce49b0d4c"}},"metadata":{}},{"name":"stdout","text":"\nTrain for 690 steps\nEpoch 1/10\n690/690 [==============================] - 231s 335ms/step - loss: 1.2434 - accuracy: 0.9273\nEpoch 2/10\n690/690 [==============================] - 218s 317ms/step - loss: 1.1827 - accuracy: 0.9833\nEpoch 3/10\n690/690 [==============================] - 218s 317ms/step - loss: 1.1794 - accuracy: 0.9867\nEpoch 4/10\n690/690 [==============================] - 218s 316ms/step - loss: 1.1785 - accuracy: 0.9869\nEpoch 5/10\n690/690 [==============================] - 218s 317ms/step - loss: 1.1780 - accuracy: 0.9880\nEpoch 6/10\n690/690 [==============================] - 218s 316ms/step - loss: 1.1788 - accuracy: 0.9869\nEpoch 7/10\n690/690 [==============================] - 218s 317ms/step - loss: 1.1771 - accuracy: 0.9884\nEpoch 8/10\n690/690 [==============================] - 218s 316ms/step - loss: 1.1746 - accuracy: 0.9909\nEpoch 9/10\n690/690 [==============================] - 218s 317ms/step - loss: 1.1747 - accuracy: 0.9906\nEpoch 10/10\n690/690 [==============================] - 218s 317ms/step - loss: 1.1749 - accuracy: 0.9908\n35/35 [==============================] - 7s 199ms/step - loss: 1.1699 - accuracy: 0.9957\n","output_type":"stream"}]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'Albert', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T10:47:38.843923Z","iopub.execute_input":"2024-04-07T10:47:38.844220Z","iopub.status.idle":"2024-04-07T10:47:38.855523Z","shell.execute_reply.started":"2024-04-07T10:47:38.844178Z","shell.execute_reply":"2024-04-07T10:47:38.854470Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"            model_name  validation_accuracy\n0                 LSTM             0.981429\n1        Random Forest             0.974286\n2  Logistic Regression             0.982857\n3                  GRU             0.970000\n4                  RNN             0.958571\n5                 BERT             0.987143\n6              Roberta             0.990000\n7                XLnet             0.982857\n8           DistilBert             0.990000\n9               Albert             0.995714\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Electra","metadata":{}},{"cell_type":"code","source":"from transformers import TFElectraModel, ElectraTokenizer\n\ntokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\nmodel = TFElectraModel.from_pretrained('google/electra-base-discriminator')\n\n\n\n# Load and preprocess the data\ndata_train = train_data_frame[['query', 'intent']]\ndata_train['category'] = pd.Categorical(data_train['intent'])\ndata_train['intent'] = data_train['category'].cat.codes\n\n# Load and preprocess the data\ndata_test = validation_data_frame[['query', 'intent']]\ndata_test['category'] = pd.Categorical(data_test['intent'])\ndata_test['intent'] = data_test['category'].cat.codes\n\n\n\n# Extract the training and testing texts and labels\ntrain_texts = data_train['query'].tolist()\ntrain_labels = data_train['intent'].tolist()\ntest_texts = data_test['query'].tolist()\ntest_labels = data_test['intent'].tolist()\n\nmax_length = 128  # Adjust based on your dataset or model's max length\n\ntrain_encodings = tokenizer.batch_encode_plus(\n    train_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\ntest_encodings = tokenizer.batch_encode_plus(\n    test_texts, \n    truncation=True, \n    padding='max_length', \n    max_length=max_length, \n    return_tensors=\"tf\",\n    pad_to_max_length=True  # Explicitly enforce padding to max_length\n)\n\n\n\n# Convert the labels to one-hot encoding\nnum_labels = len(data_train['category'].cat.categories)\ntrain_labels_encoded = tf.one_hot(train_labels, num_labels)\ntest_labels_encoded = tf.one_hot(test_labels, num_labels)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels_encoded))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels_encoded))\n\n#Define the model architecture\ninput_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\nattention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\noutput = model(input_ids, attention_mask=attention_mask)[0]\noutput = tf.keras.layers.Dense(num_labels, activation='softmax')(output[:, 0, :]) # Pooling the output\nmodel = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n#Compile and train the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\nloss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\nmetrics = ['accuracy']\n\n\n# Use smaller batch size\nbatch_size = 20\n\n\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.fit(train_dataset.batch(batch_size), epochs=10)\n\n# Evaluate the model\n\nevaluation_results = model.evaluate(test_dataset.batch(batch_size))\naccuracy = evaluation_results[1]  # Assuming accuracy is the second metric in the metrics list","metadata":{"execution":{"iopub.status.busy":"2024-04-07T10:47:38.857063Z","iopub.execute_input":"2024-04-07T10:47:38.857368Z","iopub.status.idle":"2024-04-07T11:26:18.587517Z","shell.execute_reply.started":"2024-04-07T10:47:38.857324Z","shell.execute_reply":"2024-04-07T11:26:18.586807Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da9ba27bb57b4ea1967e656beb1a6956"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d87950414ece4b5b93ac8c11efa48f85"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438200172.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafde97c0eaf4f2b8fecc9ce527c5ebe"}},"metadata":{}},{"name":"stdout","text":"\nTrain for 690 steps\nEpoch 1/10\n690/690 [==============================] - 242s 351ms/step - loss: 1.2609 - accuracy: 0.9264\nEpoch 2/10\n690/690 [==============================] - 228s 330ms/step - loss: 1.1803 - accuracy: 0.9864\nEpoch 3/10\n690/690 [==============================] - 227s 329ms/step - loss: 1.1779 - accuracy: 0.9882\nEpoch 4/10\n690/690 [==============================] - 227s 329ms/step - loss: 1.1786 - accuracy: 0.9870\nEpoch 5/10\n690/690 [==============================] - 227s 329ms/step - loss: 1.1757 - accuracy: 0.9898\nEpoch 6/10\n690/690 [==============================] - 227s 329ms/step - loss: 1.1752 - accuracy: 0.9904\nEpoch 7/10\n690/690 [==============================] - 227s 330ms/step - loss: 1.1749 - accuracy: 0.9906\nEpoch 8/10\n690/690 [==============================] - 227s 329ms/step - loss: 1.1729 - accuracy: 0.9925\nEpoch 9/10\n690/690 [==============================] - 227s 329ms/step - loss: 1.1734 - accuracy: 0.9922\nEpoch 10/10\n690/690 [==============================] - 227s 329ms/step - loss: 1.1749 - accuracy: 0.9906\n35/35 [==============================] - 7s 197ms/step - loss: 1.1786 - accuracy: 0.9857\n","output_type":"stream"}]},{"cell_type":"code","source":"# Insert data into the DataFrame\nresults_df = results_df.append({'model_name': 'Electra', 'validation_accuracy': accuracy}, ignore_index=True)\n\n# Display the DataFrame\nprint(results_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:26:18.588784Z","iopub.execute_input":"2024-04-07T11:26:18.589068Z","iopub.status.idle":"2024-04-07T11:26:18.600018Z","shell.execute_reply.started":"2024-04-07T11:26:18.589021Z","shell.execute_reply":"2024-04-07T11:26:18.599195Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"             model_name  validation_accuracy\n0                  LSTM             0.981429\n1         Random Forest             0.974286\n2   Logistic Regression             0.982857\n3                   GRU             0.970000\n4                   RNN             0.958571\n5                  BERT             0.987143\n6               Roberta             0.990000\n7                 XLnet             0.982857\n8            DistilBert             0.990000\n9                Albert             0.995714\n10              Electra             0.985714\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Evaluation","metadata":{}},{"cell_type":"code","source":"# Find the index of the row with the maximum validation accuracy\nmax_accuracy_index = results_df['validation_accuracy'].idxmax()\n\n# Retrieve the model name with the maximum validation accuracy\nbest_model_name = results_df.loc[max_accuracy_index, 'model_name']\n\nprint(f\"The best model with maximum validation accuracy is: {best_model_name}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T11:26:18.602300Z","iopub.execute_input":"2024-04-07T11:26:18.602697Z","iopub.status.idle":"2024-04-07T11:26:18.619468Z","shell.execute_reply.started":"2024-04-07T11:26:18.602643Z","shell.execute_reply":"2024-04-07T11:26:18.618668Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"The best model with maximum validation accuracy is: Albert\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:02:22.908027Z","iopub.execute_input":"2024-04-05T14:02:22.908459Z","iopub.status.idle":"2024-04-05T14:02:36.792327Z","shell.execute_reply.started":"2024-04-05T14:02:22.908399Z","shell.execute_reply":"2024-04-05T14:02:36.790888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:01:01.159088Z","iopub.execute_input":"2024-04-05T14:01:01.159645Z","iopub.status.idle":"2024-04-05T14:01:17.213668Z","shell.execute_reply.started":"2024-04-05T14:01:01.159430Z","shell.execute_reply":"2024-04-05T14:01:17.212721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:13:23.669866Z","iopub.execute_input":"2024-04-05T14:13:23.670248Z","iopub.status.idle":"2024-04-05T14:13:33.423417Z","shell.execute_reply.started":"2024-04-05T14:13:23.670196Z","shell.execute_reply":"2024-04-05T14:13:33.422417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:11:53.918344Z","iopub.execute_input":"2024-04-05T14:11:53.918799Z","iopub.status.idle":"2024-04-05T14:12:02.580467Z","shell.execute_reply.started":"2024-04-05T14:11:53.918730Z","shell.execute_reply":"2024-04-05T14:12:02.579486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:05:31.745351Z","iopub.execute_input":"2024-04-05T14:05:31.745730Z","iopub.status.idle":"2024-04-05T14:05:34.553917Z","shell.execute_reply.started":"2024-04-05T14:05:31.745682Z","shell.execute_reply":"2024-04-05T14:05:34.552957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:05:51.458575Z","iopub.execute_input":"2024-04-05T14:05:51.458939Z","iopub.status.idle":"2024-04-05T14:05:54.103478Z","shell.execute_reply.started":"2024-04-05T14:05:51.458890Z","shell.execute_reply":"2024-04-05T14:05:54.102398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:03:08.925714Z","iopub.execute_input":"2024-04-05T14:03:08.926105Z","iopub.status.idle":"2024-04-05T14:03:09.594243Z","shell.execute_reply.started":"2024-04-05T14:03:08.926044Z","shell.execute_reply":"2024-04-05T14:03:09.592791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-05T13:26:31.299269Z","iopub.execute_input":"2024-04-05T13:26:31.299668Z","iopub.status.idle":"2024-04-05T13:26:31.304902Z","shell.execute_reply.started":"2024-04-05T13:26:31.299609Z","shell.execute_reply":"2024-04-05T13:26:31.304180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}